{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268fd319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers faiss-cpu PyPDF2 nltk openai python-dotenv --quiet\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from faiss import IndexFlatL2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "import nltk\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Carrega as variáveis do arquivo .env\n",
    "load_dotenv() \n",
    "\n",
    "# 2. Busca o VALOR da variável de ambiente\n",
    "api_key_valor = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 3. Teste rápido: Se printar None, o script não achou o arquivo .env\n",
    "if api_key_valor is None:\n",
    "    print(\"Erro: Arquivo .env não encontrado ou variável OPENAI_API_KEY está vazia.\")\n",
    "else:\n",
    "    # 4. Inicializa o cliente com o VALOR\n",
    "    client = OpenAI(api_key=api_key_valor)\n",
    "\n",
    "# Download necessário para o tokenizador de sentenças\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f74329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando documentos e gerando embeddings...\n",
      "Sucesso: 13 sentenças indexadas.\n",
      "\n",
      "Buscando: Qual o nome da profissional de engenharia sanitária mencionada?\n",
      "{'text': 'Saionara Rodrigues Nogueira\\nTipo\\nProfissional\\nRegistro\\n205110-8\\nEspecialidade\\nEngenheiro de Segurança do Trabalho\\nFormação Acadêmica\\nEngenharia ambiental e Sanitária\\nExperiência Profissional\\nProfissional com experiência em mineração e setor industrial, com atuação em produção, qualidade,  \\nmeio ambiente e segurança do trabalho.', 'metadata': {'fonte': 'documento1.pdf', 'autor': 'Saionara Rodrigues Nogueira', 'categoria': 'Engenharia ambiental e Sanitária'}, 'rerank_score': 0.6127815842628479}\n",
      "{'text': 'Tenho uma abordagem analítica e estratégica para a resolução de problemas e melhoria  \\ncontínua, o que me permite implementar soluções inovadoras que aumentam a eficiência \\noperacional e asseguram a conformidade com os padrões de qualidade e regulamentações \\nambientais e segurança.', 'metadata': {'fonte': 'documento1.pdf', 'autor': 'Saionara Rodrigues Nogueira', 'categoria': 'Engenharia ambiental e Sanitária'}, 'rerank_score': 0.5378305912017822}\n",
      "Gerando resposta final...\n",
      "------------------------------\n",
      "RESPOSTA: Saionara Rodrigues Nogueira.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Download necessário para o sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO DO MODELO E ÍNDICE ---\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "dimension = 384  \n",
    "index = IndexFlatL2(dimension)\n",
    "\n",
    "\n",
    "# --- 2. FUNÇÕES DE UTILIDADE ---\n",
    "def read_pdf(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Aviso: Arquivo {file_path} não encontrado.\")\n",
    "        return \"\"\n",
    "    pdf_reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            text += content\n",
    "    return text\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Pooling: Usando a média (Mean Pooling) para melhor representação semântica\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "# --- 3. PROCESSAMENTO E INDEXAÇÃO ---\n",
    "file_paths = [\"documento1.pdf\", \"documento2.pdf\"] # Substitua pelos seus arquivos reais\n",
    "data = []\n",
    "all_embeddings = []\n",
    "\n",
    "print(\"Processando documentos e gerando embeddings...\")\n",
    "\n",
    "for file_path in file_paths:\n",
    "    text = read_pdf(file_path)\n",
    "    if not text: continue\n",
    "        \n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Metadados fictícios baseados no seu exemplo\n",
    "    if \"documento2.pdf\" in file_path:\n",
    "        metadata = {\"fonte\": file_path, \"autor\": \"Michael de Mello Oliveira\", \"categoria\": \"Geologia\"}\n",
    "    else:\n",
    "        metadata = {\"fonte\": file_path, \"autor\": \"Saionara Rodrigues Nogueira\", \"categoria\": \"Engenharia ambiental e Sanitária\"}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(sentence.strip()) < 15: continue\n",
    "        emb = get_embedding(sentence)\n",
    "        all_embeddings.append(emb)\n",
    "        data.append({\"text\": sentence, \"metadata\": metadata})\n",
    "\n",
    "if all_embeddings:\n",
    "    embeddings_array = np.vstack(all_embeddings).astype('float32')\n",
    "    index.add(embeddings_array)\n",
    "    print(f\"Sucesso: {index.ntotal} sentenças indexadas.\")\n",
    "\n",
    "# --- 4. BUSCA, FILTRO E RERANKING ---\n",
    "def search_and_filter(query, categoria=None, top_k=10):\n",
    "    query_embedding = get_embedding(query).astype('float32')\n",
    "    scores, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i, score in zip(indices[0], scores[0]):\n",
    "        if i == -1 or i >= len(data): continue\n",
    "        item = data[i]\n",
    "        \n",
    "        # Filtro de metadados\n",
    "        if categoria and item[\"metadata\"].get(\"categoria\") != categoria:\n",
    "            continue\n",
    "            \n",
    "        results.append({\n",
    "            \"text\": item[\"text\"], \n",
    "            \"metadata\": item[\"metadata\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def rerank(results, query):\n",
    "    if not results: return []\n",
    "    query_emb = get_embedding(query)\n",
    "    for res in results:\n",
    "        doc_emb = get_embedding(res[\"text\"])\n",
    "        res[\"rerank_score\"] = float(cosine_similarity(query_emb, doc_emb)[0][0])\n",
    "    \n",
    "    results.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "    return results\n",
    "\n",
    "# --- 5. INTEGRAÇÃO COM OPENAI (GERAÇÃO) ---\n",
    "def responder_com_llm(pergunta, contextos):\n",
    "    # Consolida os textos recuperados para enviar à LLM\n",
    "    contexto_unificado = \"\\n\".join([f\"- {c['text']}\" for c in contextos])\n",
    "    \n",
    "    prompt_sistema = \"\"\"Você é um assistente especializado. \n",
    "    Responda à pergunta do usuário utilizando APENAS o contexto fornecido abaixo.\n",
    "    Se a resposta não estiver no texto, diga que a informação não consta nos documentos.\"\"\"\n",
    "    \n",
    "    prompt_usuario = f\"CONTEXTO:\\n{contexto_unificado}\\n\\nPERGUNTA: {pergunta}\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt_sistema},\n",
    "                {\"role\": \"user\", \"content\": prompt_usuario}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao chamar OpenAI: {e}\"\n",
    "\n",
    "# --- 6. EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    minha_pergunta = \"Qual o nome da profissional de engenharia sanitária mencionada?\"\n",
    "    \n",
    "    print(f\"\\nBuscando: {minha_pergunta}\")\n",
    "    \n",
    "    # Passo 1: Busca e Filtro\n",
    "    achados = search_and_filter(minha_pergunta,categoria='Engenharia ambiental e Sanitária', top_k=5)\n",
    "    \n",
    "    # Passo 2: Reranking\n",
    "    refinados = rerank(achados, minha_pergunta)\n",
    "    \n",
    "    if refinados:\n",
    "        # Passo 3: Geração com OpenAI\n",
    "        print(achados[0])\n",
    "        print(achados[1])\n",
    "        print(\"Gerando resposta final...\")\n",
    "        resposta = responder_com_llm(minha_pergunta, refinados)\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"RESPOSTA: {resposta}\")\n",
    "        print(\"-\" * 30)\n",
    "    else:\n",
    "        print(\"Nenhum documento relevante encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c65fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
